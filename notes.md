
In part because of the "garden of forking paths" , transparency of the *process*
of research is crucial: (1) groups such as ours are too small to serve entire
federal government, so each project we undertake must have a pedagogical
component --- we are teaching the government about social and behavioral science
and about experiments even as we provide such theory and methods to the
government; (2) as social and behavioral scientists, we know the limitations of
experiments and of the statistical summaries that we use to make sense of them
--- we know that our results might have come out in ways that we ourselves might
not have anticipated if others were to have confronted the same data (example of
that paper on European league football analyzed by ?20? teams); (3) We value
visualization and description: any given $p$-value tells us exactly what it
should (assuming that the $p$-value arose from its own well designed process --
including pre-registration of analysis when possible and our own attention to
issues of data snooping/multiple testing/p-hacking as well as test validity. For
example, we tend to think of our statistical tests in a randomization inference
framework which allows us to assess the error rates of our tests easier than if
we had to articulate probability models of outcomes or probability models of
treatment effects apriori.); (4) we want to create policy actionable results so
we have to be attuned to both the fact that our results are *local* (i.e. tell
us about one particular group of people epxposed to a particular intervention at
a point in time) not *global* (they do not tell us in and of themselves how to
think about what would happen with large scale roll out of these policies)
**and** the fact that further questions may arise as agencies want to
incorporate our results into their processes (so, we need to make it easy for
them to re-analyze our data and discuss our nitty-gritty decisions with us); (5)
some of our work will have scientific impact, and we need to also encourage
involvement in our work from the broader scientific community.

What do we do about this?

**Peer review.** In some software development groups, the main code is never
directly changed. Rather, people "branch" or copy the main code, make a change
and then *make a request that their changes be integrated into the main code*.
This request cannot be approved by the requestor, and must be approved by a
colleague on the team. In this way, those teams institutionalize code review.
They also make one step toward engaging with the questions about the many
decisions underlying any given data analysis.

**Work in the open**

**Open source tools or tools that we make available to others**

**Use the cloud**


