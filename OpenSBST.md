---
title:  'How we should work?: A DRAFT aspirational standard operating procedure for behavioral insights teams working within governments.'
author:
- name: Jake Bowers
  afilliation: University of Illinois at Urbana-Champaign and White House Social and Behavioral Sciences Team
...


# Why this document?

A growing number of governments believe that social and behavioral scientists can help them improve their work. For example, on in September of 2015 President Barak Obama referred to the work of the new White House Social and Behavioral Sciences team when he issued Executive Order 13707 "Using Behavioral Insights To Better Serve the American People" saying:

> A growing body of evidence demonstrates that behavioral science insights --- research findings from fields such as behavioral economics and psychology about how people make decisions and act on them --- can be used to design government policies to better serve the American people.

>Where Federal policies have been designed to reflect behavioral science insights, they have substantially improved outcomes for the individuals, families, communities, and businesses those policies serve. For example, automatic enrollment and automatic escalation in retirement savings plans have made it easier to save for the future, and have helped Americans accumulate billions of dollars in additional retirement savings. Similarly, streamlining the application process for Federal financial aid has made college more financially accessible for millions of students.

Behavioral insights groups containing people with training in psychology, economics, political science, sociology and public policy have been recently founded at the national level in the UK, Germany, Australia, at the United Nations, and in the city of Washington, DC (and probably other places).

How should scientists working to improve government act? We have a good sense for how scientists should act in general. In general, science helps us solve problems and answer questions via impersonal and asynchronous collaboration: the idea is that each individual scientist is ignorant, but that groups of scientists, working across time, space, language, and technique, will gradually improve what we know. This idea, that no single person ought to have authority can be seen in Richard Feynman's 1955 address to the National Academy of Arts and Sciences:

> "I would now like to turn to a third value that science has. It is a little less direct, but not much. The scientist has a lot of experience with ignorance and doubt and uncertainty, and this experience is of very great importance, I think. We have found it of paramount importance that in order to progress we must recognize our ignorance and leave room for doubt. Scientific knowledge is a body of statements of varying degrees of certainty --- some most unsure, some nearly sure, but none absolutely certain.

> Now, we scientists are used to this, and we take it for granted that it is perfectly consistent to be unsure, that it is possible to live and not know. But I don’t know whether everyone realizes this is true. Our freedom to doubt was born out of a struggle against authority in the early days of science. It was a very deep and strong struggle: permit us to question --- to doubt --- to not be sure. I think that it is important that we do not forget this struggle and thus perhaps lose what we have gained. Herein lies a responsibility to society. (Feynman 1955, page 4--5)

We also see this idea in the very recent discussions about open science, for example the idea that scientific claims should be available to be evaluated broadly and with minimal barriers:

> "Trust is not a scientific value.  Transparency is a replacement for trust.  The irrelevance of trust is facilitated by having no central authority for truth, and by making evidence and its source available publicly.  In principle, anyone can evaluate the basis of claims, and reproduce the procedures in order to verify the claims." (Center for Open Science: Strategic Plan, page 5)

Many behavioral insights groups work within governments that adhere to the general principles of open government. The principles of open government are collaboration, participation, transparency.^[<http://www.opengovpartnership.org/about/open-government-declaration> ].  The principles of open science are integrity, reproducibility, and openness.^[ See for example some of the resources linked on Wikipedia <https://en.wikipedia.org/wiki/Open_science> and <http://sciencecommons.org/resources/readingroom/principles-for-open-science/> and see <http://book.openingscience.org/basics_background/open_science_one_term_five_schools_of_thought.html>.] Open government is supposed to be more resilient, efficient and legitimate than a government which discourages involvement from its people.^[Avoiding the word 'citizen' here because governments serve many people who are not citizens, both inside and outside of their sovereign territories.]

In this document, I suggest that we build a workflow for behavioral and social science within government remembering that science requires doubting and uncertain individuals collaborating across time and space with minimal barriers. I think that this workflow differs from the open science workflow because the purpose of the work within governments is not mainly to advance science but to serve the government and the people.

Eventually, I hope that a future version of this document can help guide choices of the growing number of social and behavioral scientists working to improve government at all levels. For now, this is an idiosyncratic draft begging for constructive input.

# Practice Humility

The fact that science requires doubt does not mean that it requires an adversarial relationship among scientists. Rather, it means that scientists must remember that what we learn about theory from one set of observations, or even many studies over time, may not translate directly into any given new circumstance: history and humans are very context dependent and they and their institutions and relationships change over time. If we are humble and embrace self-doubt when giving expert advice, then certain behaviors follow.

### Act ethically

Of course. Do no harm. IRB. Common rule.

### Articulate more than one approach to any question

Most of the behavioral insights teams are supposed to bring expertise into government. If you are on one of those teams people will say, "As an expert, given your extensive knowledge of a vast field of rigorous study, what should we do to accomplish this policy goal / improve this practice?" A scientist comfortable with doubt and ignorance, who understands that "shared understanding" or "scientific consensus" does not mean "truth", working in the government cannot always answer such questions with "I don't know." What one can do, however, is explain in plain language, the scientific consensus or debates, how the government can learn from past studies, and what some options might be given what you have read and considered.

### Recognize the expertise of the bureaucrats

What has the agency been doing already to improve processes or confront problems? Can you imagine small improvements based on what they are already doing? The people in the agency tend to know a lot more than you about how to do their work and often have hit on very good ideas that only require a little help from you to re-articulate or motivate.

### Test

If any question has more than one answer, and, even if the scientific consensus has only one answer (but the bureaucracy is doing something else), then one must test. Testing is probably the most important corollary of humility. And, in fact, a particular kind of testing follows here: a test motivated by doubt has to provide results that are not pre-determined and that must be as independent as possible of those designing and fielding the testing. Imagine for example, that a government agency has been doing things one way for many years, and now, a faction within that agency has invited the behavioral insights team to provide some advice about how to improve something or about how to solve some problem. In this case an impersonal and independent test will not only solve problems of public policy but will help resolve difficulties within the agency.

#### Plan the test and analyses

One way to help make tests serve this purpose is to encourage all stakeholders to approve of a **plan** in advance of the results. It is hard to articulate this benefit of a plan better than Paul Rosenbaum:

>Plans enable. In all aspects of life, much can be done with a plan that cannot be done without one.

>A study that follows a public plan is more convincing than a study that emerges ambiguously from a fog of data. A public plan is subject to public scrutiny before the study begins, so criticism that would otherwise surface after the fact arises before the fact, perhaps leading to a better study more resistant to legitimate criticism. If there is a public plan, and if the critic raises no objection to the plan, then criticism that could have been raised to the plan rings hollow when raised for the first time after a particular conclusion is announced. (Rosenbaum 2010, page 327)

Plan for heterogeneity of effects. It might be good practice to plan to report how different types of people might experience the policy intervention differently. In academic science, we might only need a single treatment effect to reflect on our theories. However, if we are hoping to do no harm with new policies, we may want to assess (and plan to assess) whether small groups of people may be harmed by an intervention that appears to be broadly beneficial.

#### Remember the power of randomization

When two alternative policy interventions are assigned to people at random, certain benefits emerge. Randomized tests are very persuasive (especially if the process is transparent) because they help produce what Don Kinder calls "interpretable comparisons" (Kinder and Palfrey) and also because they allow us principled ways to talk about the unobserved (Neyman, Fisher). That is, the group that gets the new idea and the group that continues with the old idea are chosen only by a flipped coin so one cannot claim that they are not comparable. After randomization one can report a difference between groups and feel confident that this difference arises from the intervention and not pre-existing differences between groups. 

Randomization also has a deeper purpose: given a reported difference between groups, one might ask, "Could this result have been different? Perhaps you got, by chance, a weird group of people in the new policy condition and, if we were to do this experiment again, we would not see any difference." In the absence of randomization, it is difficult to answer this question. With randomization, however, one can respond humbly, "Ok. If there were no difference between groups, then we would see experimental results like this, or this, or that. Our own actual results are nothing like those. This suggests to me that we don't have much evidence for the `no effects' argument." How is this response possible? If we randomized the intervention, we know *how* we randomized, this means that we can *repeat* the randomization to simulate situations implied by arguments like 'Even though you showed an effect, I think there are really no effects.'

#### Humility implies the need to test and plan

The key feature for getting folks in government to work with a behavioral insights team and to see that such collaboration is successful is that the scientists commit to testing the ideas on the table. This means that the scientists do not say 'we know best, do it our way' rather they say, 'let's give a set of good ideas a chance to compete in a fair and transparent way, and let's commit to reporting whatever we find (including ideas that we thought were good but that didn't work).' I think this idea of actually figuring out what works rather than having an argument with no data and having eventual policy arise from in essence power rather than learning from observation --- people working in government want to learn because learning helps the public.


# Practice Community

Science is a communal practice. So far we have been talking about a single study and the importance of knowing that one does not have all the answers. However, if behavioral insights teams are going to service the public, then they need to be able to improve what we know. The way that science improves what we know is via collaboration across time and space, collaboration that is as unfettered as possible, so that good ideas and energy can be contributed to any given project from unexpected sources. So, how can a behavioral insights team work in such a way as to invite collaboration with others inside and outside of the government across the world (and even with their future selves).^[Some of this idea about collaborating with a future self is in Bowers, 2011.]

## Build Trust

We want to enable citizen science because we have seen how openness
improves quality quickly within open source projects (cite) and because we
believe that citizens involved in citizen science come to see government
as a force for good (even if an often frustrating and slow force for
good). Citizens have paid us to do this work and so by making the work accessible to the public we are showing what has come of their investment.

### Report all results

Before starting a project, behavioral insights teams and their collaborators should commit to reporting all of the results laid out in the plan. Once the team has reported null results, then other agencies will know that these people will work in the public interest and are not captured by any particular political party or faction.

Reporting all results also enhances communication outside of the government. If others can see the results and processes and plans, then (1) they can learn how to conduct their own tests and policy interventions and (2) they can improve the work already done.

Reporting results can occur in many ways. The team should of course write memos to the sponsoring agency. These memos do not need to be public. However, other reporting must be public. It could occur in annual reports, on blog posts, and may also involve peer reviewed publication. Some behavioral insights teams may want to commit to publishing in open access journals under the idea that barriers should not exist between science done in the public interest and the public.

## Work in the open

Although reporting all results improves trust by agencies and by others who may want to contribute to the efforts of behavioral insights teams, people cannot contribute if the work process itself is not open or they do not know how to do the work itself. Most behavioral insights teams are small, and part of the way that they serve the government and people is by teaching others to translate what we know from the social and behavioral sciences into public policy ideas, and then to subject those ideas to planned testing. To enable others to learn, such teams should make their planning and analyses materials available in such a way that others do not need to pay a lot of money or have a job at a university in order to access the materials and learn from them, adapt them to new purposes, and use them.

Most behavioral insights teams do not tend to own the data that emerges from collaborations with agencies. So, although such teams can commit to making their own work open, they cannot commit to open data in the way that many scientists can do so. That said, the teams can make it as easy as possible for agencies to be maximally open and reap the benefits of openness. If possible, and ethical, teams should share data, including de-identified interviews and user experience research to enable others to go beyond the final analyses. Right now, sharing data with agencies is difficult --- such that standard practices might involve sending code for agencies to run on their own machines, or sending a virtual machine image for them to use on their own machines (or even lending a laptop). Teams might also be able to share simulated versions of the original data (i.e. try to follow best practices in differential privacy as results accumulate)^[<https://en.wikipedia.org/wiki/Differential_privacy>,  <http://www.cs.cmu.edu/afs/cs/academic/class/15859m-s11/www/lectures/lect0420.pdf>]. Or teams might run their own cloud based virtual machine where people can request to run analyses that are pre-screened by the team to protect research subjects and comply with the laws and regulations of their governments.

# Tools for Humble, Community Oriented, Experts

These general principles suggest some concrete actions. These actions are listed here as of 2016, but will certainly change over time.

## Action 1: Use plain text

Writing memos, reports, or analyses in formats that are propriety and/or likely to change quickly and/or cost money to read raises barriers to collaboration across both space (with others) and time (with the team itself should it desire to use materials from past studies for the future.)^[This poses a challenge for groups where the government dictates the tools.] This essay, for example, is written in [markdown](https://daringfireball.net/projects/markdown/).^[Specifically, it uses [pandoc](http://pandoc.org/) flavored markdown.]

## Action 2: Use open-source and multi-platform tools

Plain text code written for interpretation by an expensive and single platform computing language may be readable in the future, but will be of little use to those who desire to help or learn from the team. This suggests that teams only use tools like R or python or other open-source analysis languages that are available on free operating systems and across platforms.

## Action 2a: Assume others will want to reproduce the work.

The fact that one has written open source code written in plain text does not mean that others can effectively learn from or copy and improve on one's work. This means that all analyses should be written as if someone else, who is not a part of the team's social network, ought to be able to reproduce the analyses of the team (to the extent possible given data sharing limitations). Tools here include [Rmarkdown](http://rmarkdown.rstudio.com/) and processes for tracking dependencies among files like the [make](http://robjhyndman.com/hyndsight/makefiles/) system and [R packages](http://r-pkgs.had.co.nz/).^[Insert versions for python.]

## Action 3: Take advantage of the cloud

My favorite way to work in the open right now is to use [GitHub](http://github.com) because it not only encourages a workflow in which people copy and improve and change others' code, but prevents old files from being clobbered with new files, tracks and threads discussions about topics, and enables online editing and easy website creation for quick sharing of documents and results.



# End Matter

This document builds on the [*commitment of the federal government to
openness*](https://www.whitehouse.gov/open) and especially on my 
interpretation of the detailed [*US Open Government National Action Plan
3.0*](https://www.whitehouse.gov/sites/default/files/microsites/ostp/final_us_open_government_national_action_plan_3_0.pdf)

This document is currently hosted on github at <http://github/sbstusa/transparency>. Comments welcome. 

